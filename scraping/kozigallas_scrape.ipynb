{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kozig_uri = u'https://kozigallas.gov.hu/pages/jobviewer.aspx?ID={}'\n",
    "chrome_header = ('Mozilla/5.0 (Windows NT 6.2; Win64; x64) '\n",
    "                 'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                 'Chrome/32.0.1667.0 Safari/537.36')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_session():\n",
    "    session = requests.Session()\n",
    "    response = session.get('https://kozigallas.gov.hu/publicsearch.aspx',\n",
    "                           headers={'User-agent': chrome_header})\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(session, url):\n",
    "    return session.get(url, headers={'User-agent': chrome_header})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joblists(session):\n",
    "    response = get_page(session, 'https://kozigallas.gov.hu/publicsearch.aspx')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    max_page = soup.find('span', {'id': ('ctl00_ContentPlaceHolder1_'\n",
    "                                         'JobSearchForm1_JobList1_lblPageCount2')})\n",
    "    max_page = int(max_page.getText().split(':')[-1].strip())\n",
    "    print('Found {} page.'.format(max_page))\n",
    "    \n",
    "    search_uri = u'https://kozigallas.gov.hu/publicsearch.aspx?p={}'\n",
    "    return [search_uri.format(page) for page in range(1, max_page+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jobs(response):\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('div', {'class': 'joblist'}).find('table')\n",
    "    df = pd.read_html(table.prettify(), header=0)[0]\n",
    "    df = df[df.columns[:-2]]\n",
    "    df['job_id'] = [jid.get('href').split(\"'\")[1] \n",
    "                    for jid in soup.findAll('a', {'class': 'jobapplication'})]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_job(session, job_id):\n",
    "    print('.', end='')\n",
    "    response = session.get(kozig_uri.format(job_id))\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    tag = soup.find('p', {'class': 'MsoNormal'})\n",
    "    return ' '.join([tag.getText().strip() for tag in soup.findAll('p', {'class': 'MsoNormal'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    with init_session() as session:\n",
    "        print('joblist download')\n",
    "        dfs = [extract_jobs(get_page(session, joblist))\n",
    "               for joblist in get_joblists(session)]\n",
    "        print('df concat')\n",
    "        dfs = pd.concat(dfs)\n",
    "        print('downloading {} jobs'.format(len(dfs)))\n",
    "        dfs['text'] = dfs.apply(lambda row: read_job(session, row['job_id']),\n",
    "                                axis=1)\n",
    "        print('done.')\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('kozigallas20180904.csv', encoding='utf-8')\n",
    "df.to_excel('kozigallas20180904.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(text):\n",
    "    #text = unicode(text)\n",
    "    unwanted = ['\\xa0', '\\r', '\\n']\n",
    "    cleared = ''.join([char for char in text if char not in unwanted])\n",
    "    return ' '.join(cleared.split())\n",
    "\n",
    "\n",
    "def strip(text):\n",
    "    text = text.lower()\n",
    "    for char in ',.-':\n",
    "        text = text.strip().strip(char)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def process(itemlist):\n",
    "    items = itemlist.strip().split(u'•')\n",
    "    return [strip(item) for item in items if item]\n",
    "\n",
    "\n",
    "splitters = {\n",
    "    u'feladat': u'A munkakörbe tartozó, illetve a vezetői megbízással járó lényeges feladatok:',\n",
    "    u'illetmeny': u'Illetmény és juttatások:', \n",
    "    u'feltetel': u'Pályázati feltételek:',\n",
    "    u'alt_palyazat': u'Általános pályázati feltételek:',\n",
    "    u'tul_palyazat': u'Az általános pályázati feltételeken túl a pályázóval szembeni további követelmény:',\n",
    "    u'elony':    u'A pályázat elbírálásánál előnyt jelent:',\n",
    "    u'igazolas': u'A pályázat részeként benyújtandó iratok, igazolások:', \n",
    "    u'kompetencia': u'Előnyt jelentő kompetenciák:',\n",
    "    u'idopont': u'A munkakör betölthetőségének időpontja:'\n",
    "}\n",
    "\n",
    "\n",
    "def generate_order(text):\n",
    "    order = [(key, text.find(string)) for key, string in splitters.items() if not text.find(string) == -1]\n",
    "    order = sorted(order, key=lambda x: x[1])\n",
    "    return [key for key, index in order]\n",
    "    \n",
    "    \n",
    "def extract(text):\n",
    "    text = clear(text)\n",
    "    order = generate_order(text)\n",
    "    data = {key: '' for key, string in splitters.items() \n",
    "            if key not in order}\n",
    "\n",
    "    for start, end in zip(order, order[1:]):\n",
    "        selected = text.split(splitters[start])\n",
    "        item = selected[-1].split(splitters[end])\n",
    "            \n",
    "        data[start] = process(item[0])\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def unpack(df, column, fillna=None):\n",
    "    ret = pd.DataFrame((d for idx, d in df[column].iteritems()))\n",
    "    if fillna is not None:\n",
    "        ret = ret.fillna(fillna)\n",
    "    return pd.concat([df, ret], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('kozigallas20180904.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['extracted'] = data.text.apply(extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(items):\n",
    "    if items:\n",
    "        items = sum([item.split(',') for item in items], [])\n",
    "        return [item.strip() for item in items]\n",
    "    return ''\n",
    "\n",
    "\n",
    "def get_top_values(df, column, n=100):\n",
    "    occurences = Counter(sum([flatten(items) for items in df[column].values if items], []))\n",
    "    return occurences.most_common(n)\n",
    "\n",
    "\n",
    "def isonkormanyzat(text):\n",
    "    for name in [u'önkormányzat', u'polgármesteri hivatal']:\n",
    "        if name in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def clear_job(text):\n",
    "    text = re.sub(r'[0-9][0-9]+.', u'', text)\n",
    "    text = text.replace(u'1 fő', u'')\n",
    "    return text.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = unpack(data.reset_index(), 'extracted', '')\n",
    "onkormanyzat = preprocessed.loc[preprocessed[u'Közzétevő'].fillna('').map(isonkormanyzat)]\n",
    "top100 = get_top_values(onkormanyzat, 'kompetencia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(top100, columns=['kompetencia', 'szamossag'])\n",
    "   .to_excel('onkormanyzat_kompetencia_20180904.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job title cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onkormanyzat['cleaned_job'] = onkormanyzat[u'Állás megnevezése'].map(clear_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onkormanyzat.drop('index', axis=1).to_excel('onkormanyzat_20180904.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(Counter(onkormanyzat.cleaned_job.values).most_common(), columns=['munkakor', 'szamossag'])\n",
    "   .to_excel('onkormanyzat_munkakor_20180904.xlsx'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
