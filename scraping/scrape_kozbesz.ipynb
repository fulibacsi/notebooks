{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ea8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_details(url, column=\"Szerződők\"):\n",
    "    return pd.read_html(url)[0].set_index(0).transpose()[column][1]\n",
    "\n",
    "\n",
    "def get_participants_df(res):\n",
    "    links = BeautifulSoup(res.content, 'html.parser').find('table', class_=\"results_with-link\").find_all('tr')\n",
    "\n",
    "    subpages = []\n",
    "    for row in links[1:]:\n",
    "        link = row.find('a')\n",
    "        id_ = link.get_text()\n",
    "        url = 'https://kereso-core.kozbeszerzes.hu' + link.get('href')\n",
    "        try:\n",
    "            participants = extract_details(url, \"Szerződők\")\n",
    "        except:\n",
    "            print(f'FAILED participant info: {id_}')\n",
    "            participants = \"ISMERETLEN\"\n",
    "        subpages.append({'azon': id_, 'Szerződők': participants})\n",
    "\n",
    "    return pd.DataFrame(subpages)\n",
    "\n",
    "\n",
    "def get_main_df(res):\n",
    "    return pd.read_html(res.content)[0].rename(columns={'Eljárás azonosítója': 'azon'})\n",
    "\n",
    "\n",
    "def generate_df(res):\n",
    "    main_df = get_main_df(res)\n",
    "    participants_df = get_participants_df(res)\n",
    "    return main_df.merge(participants_df, on='azon')\n",
    "\n",
    "\n",
    "def scrape_page(page_id):\n",
    "    res = requests.get(f\"https://kereso-core.kozbeszerzes.hu/lista/kozbeszerzes/?oldal={page_id}\")\n",
    "    return generate_df(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27854c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "for page_id in tqdm(range(1, 501)):\n",
    "    try:\n",
    "        scraped = scrape_page(page_id)\n",
    "        tables.append(scrape_page(page_id))\n",
    "    except Exception as e:\n",
    "        print(f'FAILED: {page_id} with error: {e}')\n",
    "    \n",
    "result = pd.concat(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc129e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel('data/nyertes_kozbesz_2021-03-23--2023.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9cb205",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://kereso-core.kozbeszerzes.hu/kereses/kozbeszerzes/osszetett/?q=&alairas_datuma_0=1990-01-01&alairas_datuma_1=2020-03-24#talalatok\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251acdb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_articles(res):\n",
    "    articles = BeautifulSoup(res.content).find('div', class_=\"article__container\").find_all('div', class_=\"roll\")\n",
    "    results = []\n",
    "    for article in articles:\n",
    "        try:\n",
    "            article_link = article.find('a', class_=\"roll__title\")\n",
    "            article_url = \"https://kereso-core.kozbeszerzes.hu\" + article_link.get('href')\n",
    "            article_details = article.find('p', class_='roll__details')\n",
    "            result = {\n",
    "                'Cím': article_link.get_text().strip(),\n",
    "                \"Ajánlatkérő neve\": extract_details(article_url, 'Ajánlatkérő neve:'),\n",
    "                'Szerződők': extract_details(article_url, 'Szerződők'),\n",
    "                'Szerződés tárgya': extract_details(article_url, \"Szerződés tárgya:\"),\n",
    "                'Szerződés megkötéskori értéke': extract_details(article_url, \"Szerződés megkötéskori értéke\"),\n",
    "                'Típus': article_details.find('span', class_='roll__type').get_text().strip(),\n",
    "                'Szereződés előzménye': article_details.find('span', class_='roll__antecedent').get_text().strip(),\n",
    "                'Szereződés jellege': article_details.find('span', class_='roll__nature').get_text().strip(),\n",
    "                'Szereződés státusza': article_details.find('span', class_='roll__state').get_text().strip(),\n",
    "                'Lejárat módja': article_details.find('span', class_='roll__expiry').get_text().strip(),\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'FAILED to extract: {article}')\n",
    "        else:\n",
    "            results.append(result)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd430dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "independents = []\n",
    "\n",
    "for page_id in tqdm(range(1, 275)):\n",
    "    try:\n",
    "        res = requests.get(f\"https://kereso-core.kozbeszerzes.hu/kereses/eljarasfuggetlen/egyszeru/?q=&oldal={page_id}\")\n",
    "        articles = extract_articles(res)\n",
    "        independents.extend(articles)\n",
    "    except Exception as e:\n",
    "        print(f'FAILED: {page_id} with error: {e}')\n",
    "\n",
    "independents_df = pd.DataFrame(independents)\n",
    "independents_df.to_excel('data/kozbesz_eljaras_nelkul.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
