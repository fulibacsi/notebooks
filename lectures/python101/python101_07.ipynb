{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 101 \n",
    "## Part VII.\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping\n",
    "\n",
    "### 0. Easy file sharing\n",
    "Start your own web-server:\n",
    "- in command prompt change your directory to `notebooks/szisz/python101/data`\n",
    "- start the server with the `python -m SimpleHTTPServer` command\n",
    "\n",
    "### 1. Obtain a webpage\n",
    "\n",
    "The easiest way is to use a third party library called __`requests`__. Let's import it right away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we simply ask a server to give us an html document by requesting it through an url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_url = 'http://localhost:8000/test.html'\n",
    "response = requests.get(existing_url)\n",
    "print(response.status_code) # hopefully 200 -> successful download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_existing_url = 'http://fulibacsi.github.io/data/test1.html'\n",
    "response = requests.get(not_existing_url)\n",
    "print(response.status_code) # unfortunately 404 -> not exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Common status codes:__\n",
    "- 200: success\n",
    "- 301: permanent redirect\n",
    "- 303: redirect\n",
    "- 400: bad request\n",
    "- 401: unauthorized\n",
    "- 404: not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(existing_url)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter can render the page if it was successfully downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "if response.status_code == 200:\n",
    "    result = HTML(response.content)\n",
    "else:\n",
    "    result = 'Nah, let\\'s have a beer instead!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Process HTML\n",
    "\n",
    "#### Story time: The skeleton of a html document\n",
    "\n",
    "__HTML__ is a markup language, its basic build blocks are the `<tag>`s.<br>\n",
    "(Almost) every `<tag>` has two parts:\n",
    "\n",
    "- Opening `<tag>` \n",
    "- Closing `</tag>` \n",
    "\n",
    "Important html `<tag>`s:\n",
    "\n",
    "- `<html></html>`\n",
    "- `<head></head>`\n",
    "- `<body></body>`\n",
    "- `<div></div>`\n",
    "- `<p></p>`\n",
    "- `<span></span>`\n",
    "- `<section></section>`\n",
    "- `<a href=\"\"></a>`\n",
    "- `<img src=\"\">`\n",
    "- `<br>`\n",
    "- ```\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th></th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            ...\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    " ```\n",
    "- `<ul></ul>` / `<ol></ol>` + `<li></li>`\n",
    "    \n",
    "Tags can have different attributes:\n",
    "- `<a>`: href\n",
    "- `<img>`: src\n",
    "- id\n",
    "- class\n",
    "- anything that is not a html keyword\n",
    "    \n",
    "\n",
    "#### Let's parse it!\n",
    "\n",
    "We have a third party module for this purpose as well, the __`BeautifulSoup`__.  \n",
    "Let's import it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a soup from the downloaded document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = response.content\n",
    "soup = BeautifulSoup(document, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the created soup (which is a parsed document) we can easily access any part of the document.  \n",
    "Let's try to:\n",
    "- get the title of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get the title text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.title.getText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get the text-only version of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.getText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all the links from the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get the actual urls from the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in soup.findAll('a'):\n",
    "    print(url.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During scraping, there are a lot of different tasks that must be solve in order to get the data we need. \n",
    "In this case this demo document has important and unimportant parts. We only need the important parts.   \n",
    "#### a) Let's find the important links!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_urls = []\n",
    "for url in soup.findAll('a'):\n",
    "    if 'important_part' in url.get('href'):\n",
    "        important_urls.append(url.get('href'))\n",
    "print(important_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Let's find the important text in the document\n",
    "- select every paragraph which has \"important\" class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('p', {'class': 'important'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Whooops, something's going on! Let's investigate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_paragraphs = soup.findAll('p', {'class': 'important'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- print the text in the tags, and tags' parent's id attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in important_paragraphs:\n",
    "    print(p.getText(), p.parent.get('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see, that the \"fake\" result is from somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find(id='not_main_section'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have a hidden fake section! Let's modify our search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(id='main_content').findAll('p', {'class': 'important'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Let's find the pictures of our interest\n",
    "- Let's have the \"nice\" pictures from the div with random_images_1 class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    soup\n",
    "    .find(id='main_content')\n",
    "    .find('div', {'class': 'random_images_1'})\n",
    "    .findAll('img', {'class': 'nice'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Whoops again. Filter out the result we don't like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = (\n",
    "    soup\n",
    "    .find(id='main_content')\n",
    "    .find('div', {'class': 'random_images_1'})\n",
    "    .findAll('img', {'class': 'nice'})\n",
    ")\n",
    "nice_imgs = []\n",
    "for img in imgs:\n",
    "    if 'not' not in img['class']:\n",
    "        nice_imgs.append(img['src'])\n",
    "print(nice_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Let's do some...\n",
    "\n",
    "<img align=\"left\" width=150 src=\"pics/magic.gif\">\n",
    "<br style=\"clear:left;\"/>\n",
    "\n",
    "### Cool library of the week: tqdm\n",
    "\n",
    "#### A progressbar to follow the progress of your computation\n",
    "\n",
    "- import and try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    time.sleep(.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's use it with the LOTR example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "url ='http://ae-lib.org.ua/texts-c/tolkien__the_lord_of_the_rings_{book}__en.htm'\n",
    "LOTR = requests.get(url.format(book=1)).content\n",
    "LOTR = BeautifulSoup(LOTR, \"html.parser\").getText()\n",
    "\n",
    "def needed(token):\n",
    "    stopword = token not in nltk.corpus.stopwords.words('english')\n",
    "    number = not token.isnumeric()\n",
    "    length = len(token) > 1 # can be 2 as well\n",
    "    return stopword and number and length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(LOTR.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = filter(needed, tqdm(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcount = nltk.FreqDist(tokens)\n",
    "wordcount.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's your turn - write the missing code snippets!\n",
    "\n",
    "#### 1. Save every important link to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URI = './data/'\n",
    "filename = 'important_urls.txt'\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Let's get a random img/gif url from 9gag!\n",
    "- get the page from http://9gag.com/random\n",
    "- find the images, and get the `src` attribute's value\n",
    "- depending on the content you can find:\n",
    "    - not animated images are stored in __`img`__ tags with __`badge-item-img`__ class, in the __`src`__ attribute \n",
    "    - animated imgages are stored in __`div`__ tags with __`badge-animated-container-animated`__ class, in the __`data-mp4`__ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"http://9gag.com/random\"\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Put the previous code into a function with two arguments: number of img urls, and output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_want_fun(output, times=5):\n",
    "    pass # your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_want_fun(BASE_URI+'fun.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create a class from the previous function. \n",
    "The class should store all of the img urls.\n",
    "The class should have a method:\n",
    " - called `crawl` which crawls one random 9gag page\n",
    " - called `crawl_multiple` which crawls a number (given as argument) of 9gag pages\n",
    " - called `show_urls` which prints out the crawled urls\n",
    " - called `export` which saves the urls into a file (filename is given as argument)\n",
    " - called `reset` which empties the urls\n",
    "\n",
    "I already created the class' skeleton for you. Write your code in place of the `pass` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IWantFun(object):\n",
    "    \n",
    "    URI = \"http://9gag.com/random\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def crawl(self):\n",
    "        pass\n",
    "    \n",
    "    def crawl_multiple(self, times=5):\n",
    "        pass\n",
    "    \n",
    "    def show_urls(self):\n",
    "        pass\n",
    "    \n",
    "    def export(self, output):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nine = IWantFun()\n",
    "nine.crawl()\n",
    "nine.show_urls()\n",
    "nine.crawl_multiple(5)\n",
    "nine.show_urls()\n",
    "nine.export(BASE_URI + 'fun.txt')\n",
    "nine.reset()\n",
    "nine.show_urls()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
