{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 101\n",
    "## Part IX. - Vote results scraping\n",
    "---\n",
    "\n",
    "<img src=\"http://www.london24.com/polopoly_fs/1.3024317.1385128334!/image/4183113330.jpg_gen/derivatives/landscape_630/4183113330.jpg\" width=\"360\" align=\"left\"></img>\n",
    "<br style=\"clear:left;\"/>\n",
    "\n",
    "Scrape the 2018 hungarian voting results!\n",
    "- import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set up basic URIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOTE_BASE = 'http://valasztas.hu/dyn/pv18/szavossz/hu/'\n",
    "OVERALL = 'oevker.html'\n",
    "BASE_URI = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_response = requests.get(VOTE_BASE + OVERALL)\n",
    "print(vote_response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- extract data with beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vote_soup = BeautifulSoup(vote_response.content, \"html.parser\") \n",
    "containers = vote_soup.find('table', {'border': '1'}).findAll('tr')\n",
    "print(len(containers))\n",
    "containers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get the items out of the tablerows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = [row.findAll('td') for row in containers]\n",
    "rows[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"transform\" the data into a table-like format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in rows[:5]:\n",
    "    print([r.getText() for r in row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for our analysis, we need the region, the subregion and the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = []\n",
    "for row in rows:\n",
    "    REGIONS.append([row[0].getText(), row[2].getText(), row[1].find('a').get('href')])\n",
    "REGIONS[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Number of regions:', len(REGIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get the detailed information for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for city, region, sub_url in REGIONS:\n",
    "    print(\"Downloading and processing data for {} - {} ...\".format(city, region), end='')\n",
    "    region_response = requests.get(VOTE_BASE + sub_url)\n",
    "    region_soup = BeautifulSoup(region_response.content, \"html.parser\")\n",
    "    region_container = (region_soup\n",
    "                        .find(text='A szavazatok száma jelöltenként')\n",
    "                        .findNext('table')\n",
    "                        .findAll('tr'))\n",
    "    region_rows = [row.findAll('td') for row in region_container][1:] # remove empty header\n",
    "    # every candidate will go to a new row\n",
    "    for row in region_rows:\n",
    "        results.append([city, region] + [r.getText() for r in row][:-1]) # remove the last 'tick column'\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's look at the detailed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[:5])\n",
    "print('-' * 79)\n",
    "print('Number of candidates:', len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transform the items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_results =[]\n",
    "\n",
    "for row in results:\n",
    "    cleaned_results.append(\n",
    "        [item.replace(u'\\xa0', u'').replace(u'%', u'').strip() # replace the unneeded characters\n",
    "         for item in row]\n",
    "    )\n",
    "cleaned_results[:5]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "header = [u'region', u'subregion', u'subid', u'name', u'party', u'votes', u'votes %']\n",
    "filename = 'vote2018.csv'\n",
    "pd.DataFrame(cleaned_results, columns=header).to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
