{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1327f1c9",
      "metadata": {
        "id": "1327f1c9"
      },
      "source": [
        "# Prompt Engineering 101 - Part III.\n",
        "## Pattern-Based Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76085879",
      "metadata": {
        "id": "76085879"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5aaa5b",
      "metadata": {
        "id": "1b5aaa5b"
      },
      "source": [
        "### *Software Architecture for English*\n",
        "\n",
        "## Why Patterns?\n",
        "In software engineering, a \"Design Pattern\" is a reusable solution to a common problem.\n",
        "We apply this to AI. instead of reinventing the wheel, we use proven structures.\n",
        "\n",
        "## The Catalog\n",
        "1.  **The Persona Pattern:** \"Act as X.\" (Sets the context/bias).\n",
        "2.  **The Interview Pattern:** \"Ask me questions until you know enough.\" (Fixes vague inputs).\n",
        "3.  **The Template Pattern:** \"Fill in this form.\" (Standardizes outputs).\n",
        "4.  **The Recipe Pattern:** \"I have ingredients, give me the steps.\" (Planning).\n",
        "5.  **The Refinement Pattern:** \"Critique and fix this.\" (Quality Control).\n",
        "6.  **The Flip Pattern:** \"Ask me the questions.\" (Testing knowledge)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ba9875e",
      "metadata": {
        "id": "4ba9875e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e617bb12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e617bb12",
        "outputId": "d93595e7-b82d-4e69-f9ef-8133b5599499"
      },
      "outputs": [],
      "source": [
        "# @title üõ†Ô∏è Step 1: Laboratory Setup (Gemini API)\n",
        "# We are connecting to Google's \"Gemini 2.5 Flash\" model.\n",
        "\n",
        "# 1. Install the Google AI SDK\n",
        "!pip install -q -U google-genai\n",
        "\n",
        "import os\n",
        "import json\n",
        "import textwrap\n",
        "from google.colab import userdata\n",
        "import google.genai as genai\n",
        "from IPython.display import display, Markdown, JSON\n",
        "\n",
        "\n",
        "# 2. Configure the API Key\n",
        "# Go to https://aistudio.google.com/app/apikey to get a key.\n",
        "# It is free and takes 1 click.\n",
        "\n",
        "# 3. Use Colab Secrets (Best Practice)\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# 4. Create Wrapper Class for querying\n",
        "class GeminiModel:\n",
        "    def __init__(self, API_KEY, model_name='gemini-2.5-flash'):\n",
        "        self.client = genai.Client(api_key=API_KEY)\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def generate_content(self, contents, generation_config=None):\n",
        "        response = self.client.models.generate_content(\n",
        "            model=self.model_name,\n",
        "            contents=contents,\n",
        "            config=generation_config,\n",
        "        )\n",
        "        return response\n",
        "\n",
        "    def close(self):\n",
        "        self.client.close()\n",
        "\n",
        "\n",
        "# Free tier models have limits. In case we run out of a model quota, we'll\n",
        "# use one of the fallback models.\n",
        "#\n",
        "# Possible model names we can use are:\n",
        "# - gemini-2.5-flash-lite\n",
        "# - gemini-2.5-flash\n",
        "# - gemini-3-flash-preview\n",
        "try:\n",
        "    model = GeminiModel(GEMINI_API_KEY, model_name='gemini-2.5-flash')\n",
        "    print(\"‚úÖ Connection Established. The Engine is ready.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}. Did you paste your API key?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e94c5d",
      "metadata": {
        "id": "38e94c5d"
      },
      "source": [
        "### **Phase 1: Input Patterns (Gathering Intelligence)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a70d4d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a70d4d7",
        "outputId": "5992ab5f-1e10-4456-a25e-fd621020ab18"
      },
      "outputs": [],
      "source": [
        "# @title üé≠ Topic 1: The Persona Pattern (Advanced)\n",
        "# We used this briefly in Mod 2. Now we treat it as a \"Lens\".\n",
        "# A Persona is not just a voice; it is a KNOWLEDGE FILTER.\n",
        "\n",
        "topic = \"Cryptocurrency\"\n",
        "\n",
        "# Persona A: The Skeptic\n",
        "prompt_a = f\"\"\"\n",
        "Act as a skeptical, risk-averse Forensic Accountant.\n",
        "Analyze the concept of '{topic}'. Focus on fraud risks and regulation.\n",
        "\"\"\"\n",
        "\n",
        "# Persona B: The Believer\n",
        "prompt_b = f\"\"\"\n",
        "Act as a visionary Web3 Venture Capitalist.\n",
        "Analyze the concept of '{topic}'. Focus on future potential and disruption.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- THE SKEPTIC ---\")\n",
        "display(Markdown(model.generate_content(prompt_a).text[:500] + \"...\\n\"))\n",
        "\n",
        "print(\"--- THE BELIEVER ---\")\n",
        "display(Markdown(model.generate_content(prompt_b).text[:500] + \"...\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be3d2afb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "be3d2afb",
        "outputId": "9245f1f1-86ae-4d78-c00d-384a96920cf5"
      },
      "outputs": [],
      "source": [
        "# @title üé§ Topic 2: The Interview Pattern (The \"Flipped\" Interaction)\n",
        "# PROBLEM: You don't know what to tell the AI.\n",
        "# SOLUTION: Make the AI ask YOU questions.\n",
        "\n",
        "# This is the \"God Mode\" of prompting. It prevents \"Garbage In\".\n",
        "\n",
        "context = \"I want to launch a new coffee shop.\"\n",
        "\n",
        "interview_prompt = f\"\"\"\n",
        "CONTEXT: {context}\n",
        "\n",
        "TASK:\n",
        "I want you to write a marketing strategy for me.\n",
        "BUT, you do not have enough information yet.\n",
        "Do not generate the strategy yet.\n",
        "Instead, ask me questions, one by one, to gather the info you need (Location, Target Audience, Budget).\n",
        "Stop and wait for my answer after each question.\n",
        "\"\"\"\n",
        "\n",
        "# Note: In a notebook, we simulate the 'wait' by just showing the first question.\n",
        "response = model.generate_content(interview_prompt).text\n",
        "display(Markdown(f\"**AI:** {response}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5398a351",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "5398a351",
        "outputId": "1145367b-c76d-4445-c331-bcce029902e6"
      },
      "outputs": [],
      "source": [
        "# @title üîÑ Topic 3: The Flip Pattern (Quiz Master)\n",
        "# PROBLEM: I want to test my own knowledge.\n",
        "# PATTERN: \"Ask me questions about X, and correct my answers.\"\n",
        "\n",
        "topic = \"The French Revolution\"\n",
        "\n",
        "flip_prompt = f\"\"\"\n",
        "Act as a strict History Professor.\n",
        "I want you to test my knowledge on {topic}.\n",
        "Ask me a hard question. Wait for my answer.\n",
        "Then grade me and ask the next one.\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(f\"**AI:** {model.generate_content(flip_prompt).text}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ba4b1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "47ba4b1c",
        "outputId": "5b8847fd-8491-4468-d5c9-132b3b6ca4fc"
      },
      "outputs": [],
      "source": [
        "# @title üß™ LAB 1: The Consultant Bot\n",
        "# SCENARIO: You are a consultant. A client comes to you and says \"My sales are down.\"\n",
        "# That is not enough info.\n",
        "\n",
        "# TASK: Write a prompt using the INTERVIEW PATTERN that forces the AI to act as a\n",
        "# \"Diagnostic Doctor\" to find the root cause.\n",
        "\n",
        "# --- STUDENT WORKSPACE ---\n",
        "my_problem = \"My restaurant is losing money.\"\n",
        "my_persona = \"Senior Business Analyst\"\n",
        "\n",
        "consultant_prompt = f\"\"\"\n",
        "{my_persona}\n",
        "{my_problem}\n",
        "\"\"\"\n",
        "# -------------------------\n",
        "\n",
        "display(Markdown(model.generate_content(consultant_prompt).text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42447cdb",
      "metadata": {
        "id": "42447cdb"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a49a20",
      "metadata": {
        "id": "05a49a20"
      },
      "source": [
        "### **Phase 2: Refinement Patterns (Polishing)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9145aaa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "b9145aaa",
        "outputId": "734ec0ee-cdfe-49d5-eb1d-ecd7d4e54d92"
      },
      "outputs": [],
      "source": [
        "# @title üßê Topic 4: The Critique/Review Pattern\n",
        "# PROBLEM: The AI's first draft is usually \"average\".\n",
        "# PATTERN: \"Generate -> Critique -> Refine\".\n",
        "\n",
        "draft_email = \"Hey boss, I need a raise. I work hard. Thx.\"\n",
        "\n",
        "critique_prompt = f\"\"\"\n",
        "Input Text: \"{draft_email}\"\n",
        "\n",
        "Task:\n",
        "1. Act as a Corporate HR Director. Critique the input text for tone and persuasion.\n",
        "2. List 3 specific weaknesses.\n",
        "3. Do NOT rewrite it yet. Just critique.\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(model.generate_content(critique_prompt).text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c4c2d8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "2c4c2d8d",
        "outputId": "bef0369c-f3fc-42d5-afc0-14fc7d16c30c"
      },
      "outputs": [],
      "source": [
        "# @title ‚ú® Topic 5: The Refinement Pattern (The Fixer)\n",
        "# Continuing from above... now we apply the fix.\n",
        "\n",
        "refinement_prompt = f\"\"\"\n",
        "Based on the critique above (Tone is too casual, lacks data, unprofessional),\n",
        "rewrite the email to be professional, persuasive, and data-driven.\n",
        "\"\"\"\n",
        "\n",
        "# We chain the history manually here for the demo\n",
        "final_prompt = (\n",
        "    critique_prompt\n",
        "    + \"\\n\"\n",
        "    + model.generate_content(critique_prompt).text\n",
        "    + \"\\n\"\n",
        "    + refinement_prompt\n",
        ")\n",
        "\n",
        "display(Markdown(model.generate_content(final_prompt).text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee63227",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "4ee63227",
        "outputId": "64dcd099-d966-458b-dd9c-ea7128c4c7b1"
      },
      "outputs": [],
      "source": [
        "# @title üß© Topic 6: The Decomposition Pattern\n",
        "# PROBLEM: \"Write a book\" is too big. The AI will hallucinate or rush.\n",
        "# PATTERN: Break it down.\n",
        "\n",
        "complex_task = \"Write a comprehensive guide on how to survive in the wilderness.\"\n",
        "\n",
        "decomposition_prompt = f\"\"\"\n",
        "TASK: {complex_task}\n",
        "\n",
        "Do not write the guide yet.\n",
        "Instead, break this task down into a Table of Contents with 5 Chapters.\n",
        "For each chapter, list 3 bullet points of key topics to cover.\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(model.generate_content(decomposition_prompt).text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd00861a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "cd00861a",
        "outputId": "0a159692-ba18-43fd-d197-1cda5cbc40f6"
      },
      "outputs": [],
      "source": [
        "# @title üòà LAB 2: The Devil's Advocate\n",
        "# SCENARIO: You are submitting a proposal to your boss. You want to know where they will attack it.\n",
        "# TASK: Use the PERSONA + CRITIQUE pattern to simulate a hostile review.\n",
        "\n",
        "# --- STUDENT WORKSPACE ---\n",
        "my_proposal = \"We should let all employees work from home forever to save money on office rent.\"\n",
        "\n",
        "advocate_prompt = f\"\"\"\n",
        "{my_proposal}\n",
        "\"\"\"\n",
        "# -------------------------\n",
        "\n",
        "display(Markdown(model.generate_content(advocate_prompt).text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "512796b6",
      "metadata": {
        "id": "512796b6"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "840d6c61",
      "metadata": {
        "id": "840d6c61"
      },
      "source": [
        "### **Phase 3: Creation Patterns (Generating Assets)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e26c002b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "e26c002b",
        "outputId": "be238ce4-4089-47ee-8220-2a05c578ff0a"
      },
      "outputs": [],
      "source": [
        "# @title üìù Topic 7: The Template Pattern\n",
        "# PROBLEM: I need data in a specific format (e.g., a bug report, a citation).\n",
        "# PATTERN: \"Here is the mold. Pour the data into it.\"\n",
        "\n",
        "bug_data = \"The login button is broken on the mobile app when I use an iPhone.\"\n",
        "\n",
        "template = \"\"\"\n",
        "- Title: [Short Description]\n",
        "- Severity: [Low/Med/High]\n",
        "- Environment: [Device/OS]\n",
        "- Steps to Reproduce:\n",
        "- 1. [Step 1]\n",
        "- 2. [Step 2]\n",
        "...\n",
        "- n. [Step n]\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Take this data: \"{bug_data}\"\n",
        "Fill it into this template:\n",
        "{template}\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(model.generate_content(prompt).text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "922ef72f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "922ef72f",
        "outputId": "5a1642a1-625f-46ad-94d2-825f84ba3944"
      },
      "outputs": [],
      "source": [
        "# @title üç≥ Topic 8: The Recipe Pattern\n",
        "# PROBLEM: I know the result, I need the steps.\n",
        "# PATTERN: \"I want to eat X. Give me the recipe.\"\n",
        "\n",
        "goal = \"I want to have 10,000 followers on LinkedIn in 6 months.\"\n",
        "\n",
        "recipe_prompt = f\"\"\"\n",
        "GOAL: {goal}\n",
        "Provide a step-by-step execution plan (Recipe) to achieve this.\n",
        "Include:\n",
        "- Daily habits\n",
        "- Weekly milestones\n",
        "- Content strategy\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(model.generate_content(recipe_prompt).text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a42a61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "e4a42a61",
        "outputId": "40abf12f-bd1d-4fb5-9713-f102758b9e87"
      },
      "outputs": [],
      "source": [
        "# @title üé® Topic 9: The Visualization Pattern (ASCII/Mermaid)\n",
        "# PROBLEM: LLMs are text-only.\n",
        "# PATTERN: Ask for \"Text-based visual formats\" like ASCII art or Mermaid.js.\n",
        "\n",
        "process = \"A user logs in. If password is correct, go to Dashboard. If wrong, show Error.\"\n",
        "\n",
        "viz_prompt = f\"\"\"\n",
        "Visualize this process logic: \"{process}\"\n",
        "Output it as a Mermaid.js Flowchart code block.\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(model.generate_content(viz_prompt).text))\n",
        "# Note: You can paste the output into https://mermaid.live"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56cc571d",
      "metadata": {
        "id": "56cc571d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85b3fe6",
      "metadata": {
        "id": "f85b3fe6"
      },
      "source": [
        "### **Phase 4: Meta-Patterns (Advanced)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbbcac60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbbcac60",
        "outputId": "e3a7aaef-8d31-4f50-b3d7-70ea424f09d1"
      },
      "outputs": [],
      "source": [
        "# @title ü§ñ Topic 10: The Meta-Prompt (AI Writing AI)\n",
        "# PROBLEM: I don't know how to write a good prompt for this task.\n",
        "# PATTERN: \"Write a prompt for me.\"\n",
        "\n",
        "task = \"I want to use AI to grade student essays.\"\n",
        "\n",
        "meta_prompt = f\"\"\"\n",
        "You are an expert Prompt Engineer.\n",
        "I need a prompt that will allow an AI to grade 10th-grade history essays.\n",
        "The prompt needs to include a Rubric, Grading Scale, and feedback instructions.\n",
        "\n",
        "Write the prompt for me.\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(model.generate_content(meta_prompt).text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d49e00a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "d49e00a4",
        "outputId": "f5389380-953f-4248-aaa0-3057cae681a2"
      },
      "outputs": [],
      "source": [
        "# @title üß± Topic 11: The Few-Shot Chain\n",
        "# PROBLEM: One example isn't enough.\n",
        "# PATTERN: Show the AI a pattern of \"Input -> Reasoning -> Output\".\n",
        "\n",
        "# This teaches the AI *how to think*, not just what to say.\n",
        "few_shot_chain = \"\"\"\n",
        "Input: \"The car won't start.\"\n",
        "Reasoning: The battery might be dead, or the starter is broken.\n",
        "Response: \"Check if the lights turn on. If not, it's the battery.\"\n",
        "\n",
        "Input: \"The internet is slow.\"\n",
        "Reasoning: The router might be far away, or the ISP is having issues.\n",
        "Response: \"Try moving closer to the router or restarting it.\"\n",
        "\n",
        "Input: \"My coffee tastes burnt.\"\n",
        "Reasoning:\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(model.generate_content(few_shot_chain).text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f3bf8c",
      "metadata": {
        "id": "22f3bf8c"
      },
      "outputs": [],
      "source": [
        "# @title üß† LAB 3: The System Builder (Capstone Prep)\n",
        "# TASK: Combine 3 patterns to solve a problem.\n",
        "# Scenario: You need to hire a Python Developer.\n",
        "\n",
        "# Step 1: Use Decomposition to list the requirements.\n",
        "# Step 2: Use Template to create a Job Description.\n",
        "# Step 3: Use Interview Pattern to generate 5 interview questions.\n",
        "\n",
        "# --- STUDENT WORKSPACE ---\n",
        "step1_prompt = \"\"\"\n",
        "\"\"\"\n",
        "step1_response = model.generate_content(step1_prompt).text\n",
        "print(\"STEP1:\")\n",
        "display(Markdown(step1_response))\n",
        "\n",
        "step2_prompt = f\"\"\"\n",
        "{step1_response}\n",
        "\"\"\"\n",
        "step2_response = model.generate_content(step2_prompt).text\n",
        "print(\"STEP2:\")\n",
        "display(Markdown(step2_response))\n",
        "\n",
        "step3_prompt = f\"\"\"\n",
        "{step2_response}\n",
        "\"\"\"\n",
        "step3_response = model.generate_content(step3_prompt).text\n",
        "print(\"STEP3:\")\n",
        "display(Markdown(step3_response))\n",
        "# -------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c276f908",
      "metadata": {
        "id": "c276f908"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40950a0b",
      "metadata": {
        "id": "40950a0b"
      },
      "source": [
        "### **Topic 12: Anti-Patterns (What to Avoid)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "332fd9b6",
      "metadata": {
        "id": "332fd9b6"
      },
      "source": [
        "*(Discussion Only)*\n",
        "\n",
        "1. **The \"Kitchen Sink\" Prompt:** Trying to do too much in one prompt. (Solution: Decomposition).\n",
        "2. **The \"Mind Reader\":** Assuming the AI knows your company context. (Solution: Persona + Context).\n",
        "3. **The \"Nag\":** Repeating \"Don't do X\" 50 times. (Solution: Negative Constraints at the end)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e686c153",
      "metadata": {
        "id": "e686c153"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79db99b3",
      "metadata": {
        "id": "79db99b3"
      },
      "source": [
        "## üè† Homework: The Socratic Tutor\n",
        "\n",
        "### The Scenario\n",
        "You are building an educational bot for a history class.\n",
        "The goal is NOT to give the student the answer.\n",
        "The goal is to **guide** the student to the answer by asking questions (Socratic Method).\n",
        "\n",
        "### The Task\n",
        "Write a robust prompt that:\n",
        "1.  **Persona:** Acts as Socrates (wise, patient, inquisitive).\n",
        "2.  **Pattern:** Uses the **Flip/Interview Pattern** (never answers, only asks).\n",
        "3.  **Constraint:** If the student gets it wrong, give a hint, not the answer.\n",
        "4.  **Template:** At the end of the session, output a \"Report Card\" in a specific format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de6ffee6",
      "metadata": {
        "id": "de6ffee6"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE GOES HERE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
