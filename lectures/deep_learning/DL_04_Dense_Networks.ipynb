{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/DL.png\" width=110 align=\"left\" style=\"margin-right: 10px\">\n",
    "\n",
    "# Introduction to Deep Learning\n",
    "\n",
    "## 04. Dense Networks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending Backpropagation\n",
    "\n",
    "There are several ways to extend the backpropagation algorithm. We can change the activation function, the cost function, introduce regularization to the system or even use different optimization methods instead of the gradient descent. \n",
    "\n",
    "In this notebook we'll discover what are the most commonly used modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "\n",
    "Changing the output function is one of the most direct way to change the network, and it is critical to match the function with the input data.\n",
    "\n",
    "#### Sigmoid\n",
    "\n",
    "<img src=\"./pics/functions/sigmoid.png\" width=350 align=\"left\">\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\text{Range: } & \\{0...1\\} \\\\\n",
    "    \\sigma(x)      & = \\frac{1}{1 + e^{-x}} \\\\\n",
    "    \\sigma'(x)     & = \\sigma (x) \\left( 1 - \\sigma(x) \\right)\n",
    "\\end{align}$$\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "#### Hyperbolic tangent\n",
    "\n",
    "<img src=\"./pics/functions/tanh.png\" width=350 align=\"left\">\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\text{Range: } & \\{-1...1\\} \\\\\n",
    "    \\tanh(x)       & = \\frac{1 - e^{-2x}}{1 + e^{-2x}} \\\\\n",
    "    \\tanh'(x)      & = 1 - \\frac{\\left( e^x - e^{-x} \\right) ^2}{ \\left( e^x + e^{-x} \\right)^2} \\\\\n",
    "                   & = 1 - \\tanh^2(x)\n",
    "\\end{align}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### Linear\n",
    "\n",
    "<img src=\"./pics/functions/linear.png\" width=350 align=\"left\">\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\text{Range: } & \\{-\\inf...\\inf\\} \\\\\n",
    "    f(x)           & = x \\\\\n",
    "    f'(x)          & = 1\n",
    "\\end{align}$$\n",
    "\n",
    "<br><br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "#### ReLU - Rectified Linear Unit\n",
    "\n",
    "<img src=\"./pics/functions/relu.png\" width=350 align=\"left\">\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\text{Range: }    & \\{0...\\inf\\} \\\\\n",
    "    \\mathrm{relu}(x)  & = \\max \\left(0, x \\right) \\\\\n",
    "    \\mathrm{relu}'(x) & = { \\begin{cases} \n",
    "                                0 & {\\text{for }} x < 0\\\\\n",
    "                                1 & {\\text{for }} x \\leq 0\n",
    "                            \\end{cases} }\n",
    "\\end{align}$$\n",
    "\n",
    "<br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "#### Leaky ReLU - Rectified Linear Unit\n",
    "\n",
    "<img src=\"./pics/functions/leaky_relu.png\" width=350 align=\"left\">\n",
    "\n",
    "A parametrized version of ReLU. Instead of setting the output to zero, multiply it with a very small number, tipical choice is $\\alpha = 0.01$. \n",
    "\n",
    "$$\\begin{align}\n",
    "    \\text{Range: }            & \\{-\\inf...\\inf\\} \\\\\n",
    "    \\mathrm{relu_{leaky}}(x)  & = \\max \\left(\\alpha x, x \\right) \\\\\n",
    "    \\mathrm{relu_{leaky}}'(x) & = { \\begin{cases} \n",
    "                                        \\alpha & {\\text{for }} x < 0\\\\\n",
    "                                        1      & {\\text{for }} x \\leq 0\n",
    "                                    \\end{cases} }\n",
    "\\end{align}$$\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "#### ELU - Exponential Linear Unit\n",
    "\n",
    "<img src=\"./pics/functions/elu.png\" width=350 align=\"left\">\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\text{Range: }   & \\{-\\inf...\\inf\\} \\\\\n",
    "    \\mathrm{elu}(x)  & = { \\begin{cases} \n",
    "                               \\alpha \\left(e^{x} - 1\\right) & {\\text{for }} x < 0 \\\\\n",
    "                               x                             & {\\text{for }} x \\leq 0\n",
    "                           \\end{cases} } \\\\\n",
    "    \\mathrm{elu}'(x) & = { \\begin{cases} \n",
    "                                f(x) + \\alpha & {\\text{for }} x < 0 \\\\\n",
    "                                1 & {\\text{for }} x \\leq 0\n",
    "                            \\end{cases} }\n",
    "\\end{align}$$\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "#### Softmax\n",
    "\n",
    "Softmax activation function will turn output neuron activation values into probabilities. The sum of the outputs of the network will be always 1 and each output should have a nonzero value. The calculation can only be done knowing all of the neuron outputs.\n",
    "Let's see how this change will be reflected in the derivatives.\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\text{Range: } & \\{0...1\\} \\\\\n",
    "    \\sigma(x_i)    & = \\frac{e^x_i}{\\sum^n_{j=1}(e^x)} \\\\\n",
    "    \\sigma'(x_i)   & = \\sigma(x_j)\\left(\\delta_{ij} - \\sigma(x_i) \\right) \\\\\n",
    "    \\text{where }  & \\delta_{ij} = { \\begin{cases} \n",
    "                                         0 & {\\text{if }} i \\neq j \\\\\n",
    "                                         1 & {\\text{for }} i = j\n",
    "                                     \\end{cases} }\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost functions\n",
    "\n",
    "**Cost** or **loss** functions are the **same as** the **error** functions we used previously during our backpropagation. In reality, we can use the same quadratic error function as cost function in a deep network as well.  \n",
    "The overall goal does not change: we would like to find the set of weights that minimizes the error on the output. However there are several better candidates for this purpose than the quadratic function.  \n",
    "We'll add a small modification to our error computation on the neuron (which we refer as *delta*): \n",
    "\n",
    "$$\\begin{align}\n",
    "    \\delta^n_k \n",
    "    & = \\frac{\\partial C^n}{\\partial a^n_k}\n",
    "    = \\frac{\\partial C^n}{\\partial y^n_{j}} f'\\left( a^n_j \\right)\n",
    "\\end{align}$$\n",
    "\n",
    "Instead of fixing the error on a special case, we'll leave the door open for any function, and compute the derivatives based on the loss function.  \n",
    "Let's got through the most common cost functions with their advantages and use cases.\n",
    "\n",
    "#### Regression\n",
    "\n",
    "##### Mean Squared Error Loss\n",
    "\n",
    "Regression problems requires direct measurement on the error. Notice that we measure multiple outcome and compute the average of the errors.\n",
    "\n",
    "$$C = \\frac{1}{m} \\sum_k \\left(t - y \\right)^2 $$\n",
    "\n",
    "\n",
    "##### Mean Squared Logarithmic Error Loss \n",
    "\n",
    "There are cases when the expected output of the regression has a large range range. Large values in the error causes large changes in the weights, so it is useful to measure the error on the logarithmic scale. Unscaled data is expected as input.\n",
    "\n",
    "$$C = \\frac{1}{m} \\sum_k \\left( \\log(t + 1) - \\log(y + 1) \\right)^2 $$\n",
    "\n",
    "\n",
    "##### Mean Absolute Error Loss\n",
    "\n",
    "MAE is more robust to outliers, so if the target variable contains large values, it is appropriate to use this loss function. MAE can result in large gradient values which in turn leads to convergence problems.\n",
    "\n",
    "$$C = \\frac{1}{m} \\sum_k \\left| t - y \\right|$$\n",
    "\n",
    "#### Binary classification\n",
    "\n",
    "##### Binary Cross-Entropy Loss\n",
    "\n",
    "Target value range: $\\{0, 1\\}$  \n",
    "Also referred as log loss.  \n",
    "The average difference of the distribution of the target and prediction distribution in case of predicted **class = 1**. It is the preferred loss function when using maximum likelihood optimization (more on that later). Note that it should be used with sigmoid activation function.\n",
    "\n",
    "$$C = - \\frac{1}{m} \\sum^m_i{\\left[t\\log(y_i) + (1 - t)\\log(1 - y_i)\\right]}$$\n",
    "\n",
    "##### Hinge Loss\n",
    "\n",
    "Target value range: $\\{-1, 1\\}$  \n",
    "Created for SVM, punishes different incorrect sign. It is used for binary classification problem. Your result may vary, in some cases it has better performance than cross-entropy.\n",
    "\n",
    "$$C = \\sum^m_i{\\max \\left( 0, 1 - t \\cdot y_i \\right)}$$\n",
    "\n",
    "##### Squared Hinge Loss\n",
    "\n",
    "Target value range: $\\{-1, 1\\}$  \n",
    "Hinge Loss ^2, smoothens the loss curve and finds the solution that maximizes the margin around the decision plane between the classes. It won't provide probabilistic information about the decision. It should be used in tandem with tanh activation.\n",
    "\n",
    "$$C = \\sum^m_i \\left( \\max \\left( 0, 1 - t \\cdot y_i \\right)^2 \\right)$$\n",
    "\n",
    "##### Cosine similarity\n",
    "\n",
    "Target value range: $\\{-1, 1\\}$  \n",
    "It is used to measure similarity between vectors. Cosine similarity values have different meanings: -1 = total opposite, 0 = orthogonal, 1 = the same.\n",
    "\n",
    "$$C = \\frac{t \\cdot y}{∥t∥ ∥y∥}$$\n",
    "\n",
    "\n",
    "#### Multiclass classification\n",
    "\n",
    "##### Multi-Class Cross-Entropy Loss\n",
    "\n",
    "Target value range: $\\{0, n\\}$  \n",
    "The average difference of the distribution of the target and prediction distribution **for every class**. Specifically for ML. Perfect score: entropy = 0. Requires $n$ output nodes (one for each class).\n",
    "\n",
    "$$C = - \\frac{1}{N} \\sum^N_n{\\left[t_n \\log(y_n) + (1 - t_n)\\log(1 - y_n) \\right]}$$\n",
    "\n",
    "##### Sparse Multiclass Cross-Entropy Loss\n",
    "\n",
    "Target value range: $\\{0, n\\}$  \n",
    "The same as Multi-Class Cross-Entropy Loss, but doesn't require the one-hot encoding of the target variable into $n$ distinct feature. It still requires $n$ output nodes and it is preferrably used with softmax activation function.\n",
    "\n",
    "$$C = - \\frac{1}{N} \\sum^N_n{\\left[t_n \\log(y_n) + (1 - t_n)\\log(1 - y_n) \\right]}$$\n",
    "\n",
    "##### Kullback Leibler Divergence Loss\n",
    "\n",
    "Target value range: $\\{0, n\\}$  \n",
    "aka relative entropy: difference from baseline distribution, how much info is lost if prediction used instead of target. Used for more sophisticated cases eg. approximating an another function. in multiclass case = Multi-Class Cross-Entropy Loss, so $n$ output node is required.\n",
    "\n",
    "$$C = \\sum^N_n {t_n \\log \\left({t_n}\\Big/{y_n} \\right)}$$\n",
    "\n",
    "#### Recommendations\n",
    "\n",
    "- Regression: MSE\n",
    "- Binary classification: Cross Entropy\n",
    "- Muliclass classification: Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "> *With four parameters I can fit an elephant,  \n",
    "> and with five I can make him wiggle his trunk.* - [Von Neumann](https://www.johndcook.com/blog/2011/06/21/how-to-fit-an-elephant/)\n",
    "\n",
    "The more parameter a model has the more susceptible to overfitting. There are several way to prevent this: \n",
    "- We can split the data into train-test-validation datasets and measure error on validation sets, stop training once the error starts to increase on validation set and finally evaluate the model on the test set.\n",
    "- We can decrease the size of the parameters and the size of the network with it, but larger networks has more expression and predictive power.\n",
    "- It is also possible to handle overfitting by introducing a regularization punishment term to the cost function which will control the weight values.\n",
    "- Other possible wy to reduce overfitting is to randomly select and temporarily drop neurons during each training batch.\n",
    "\n",
    "Let's go through the effect of these methods one-by-one.\n",
    "\n",
    "#### L1 \n",
    "\n",
    "L_1 regularization uses the absolute value of the weights to prevent large changes in the weights except when it is an impactful. L_1 regularization will shrink the weights by a constant amount towards 0.\n",
    "\n",
    "It can be described as: \n",
    "\n",
    "$$C = C_0 + \\frac{\\lambda}{m} \\sum_w{|w|}$$\n",
    "\n",
    "Where $C_0$ is the original cost function. In case of cross entropy we get: \n",
    "\n",
    "$$\n",
    "C = -\\frac{1}{m} \\sum_{xi} \n",
    "    \\left[ t_i \\log a^L_i \n",
    "           + (1 - t_i) \\log(1 - y^L_i) \n",
    "    \\right]\n",
    "    + \\lambda \\sum_i{|w_i|}\n",
    "$$\n",
    "\n",
    "#### L2\n",
    "\n",
    "L_2 regularization uses the squared weights to prevent large changes in the weights except when it is an impactful. L_2 regularization will shrink the weights by the amount proportional to the value of the weights. It is also referred as weight decay as well.\n",
    "\n",
    "$$C = C_0 + \\frac{\\lambda}{2m} \\sum_w w^2$$\n",
    "\n",
    "Where $C_0$ is the original cost function. In case of cross entropy we get: \n",
    "\n",
    "$$\n",
    "C = -\\frac{1}{m} \\sum_{xi} \n",
    "    \\left[ t_i \\log a^L_i \n",
    "           + (1 - t_i) \\log(1 - y^L_i) \n",
    "    \\right]\n",
    "    + \\frac{\\lambda}{2m} \\sum_w w^2\n",
    "$$\n",
    "\n",
    "#### Dropout\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*iWQzxhVlvadk6VAJjsgXgg.png\" width=500>By <a href=\"http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf\">Srivastava, Nitish, et al. ”Dropout: a simple way to prevent neural networks from overfitting”, JMLR 2014</a>\n",
    "\n",
    "Instead of transforming the cost function, dropout regularization (temporarily) modifies the network itself by removing some of the neurons from part of the training process (we'll discuss different training strategies in the next section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers (update rules)\n",
    "\n",
    "#### Stochastic Gradient Descent\n",
    "\n",
    "The algorithm we implemented in the previous chapter was actually the Stochastic Gradient descent. It is using one training example at a time to update the weights. Usually we shuffle the dataset instead of going through each sample one by one.  \n",
    "Let's revisit the weight update rules with a small change: let's use a variation called mini-batch stochasitc gradient descent. Instead of handling one training sample at a time we are going to compute the result of $m$ sample at once and use the average error on those result to update the weights. Typical $m$ sizes are powers of 2, starting from $m = 2^6 = 64$.\n",
    "\n",
    "- **feedforward**: \n",
    "    - set input to $y^{x,1}$\n",
    "    - for every $l = 2, 3, ... L$: $y^{x,l} = w^l y^{x, l-1}$\n",
    "- **backpropagation**:\n",
    "    - output error: $\\delta^{x,L} = \\nabla_y C_x \\odot \\sigma'(a^{x,L})$\n",
    "    - for every $l = L-1, L-2, ... 2$: $\\delta^{x,l} = \\left( \\left( w^{l+1} \\right)^T \\delta^{x,l+1} \\right) \\cdot f'\\left( a^{x, l - 1} \\right)^T$\n",
    "- **weight update**:\n",
    "    - weights: $w^l = w^l - \\frac{\\alpha}{m} \\sum_x {\\delta^{x,l} \\left(y^{x,l-1}\\right)^T }$\n",
    "\n",
    "#### Gradient Descent\n",
    "\n",
    "Gradient descent is a special case of mini-batch stochastic gradient descent where $m$ equals to $N$, the number of training samples. It is very rarely used, since it requires computing every result for every iteration. \n",
    "It is possible to extend gradient descent with regularization techniques.\n",
    "\n",
    "#### Gradient Descent with momentum\n",
    "\n",
    "Finding the optimum is not always a straightforward process. The gradients aren't pointing to the global optimum directly, they are oscillating. To smoothen this oscillation, and give a better general direction, we are going to give an overall momentum to the direction of the change by incrementally building the speed of change. \n",
    "We are going to use mini-batch updates, and for each batch, we compute $\\delta$ and create the speed of delta, called $V_\\delta$ using the following formula:\n",
    "$$V_\\delta = \\beta V_\\delta + \\left(1 - \\beta\\right)\\delta$$\n",
    "where $\\beta$ is the friction parameter, and use this speed for the updates:\n",
    "$$w = w - \\alpha V_\\delta$$\n",
    "This change will smoothen the gradients. Typical value for $\\beta$ is 0.9 which is basically the average of the last 10 gradient.\n",
    "\n",
    "#### RMSprop - Root Mean Squared Propagation\n",
    "\n",
    "The goal of the method is to further accelerate the learning process by modifying the update rule. Similarly to gradient descent with momentum method, we are trying to gather the general direction towards the optimum by conserving the momentum of the gradients from the previous iterations. This time however we will use the square of the gradients from each mini-batch:\n",
    "$$S_\\delta = \\beta_2 S_\\delta + \\left(1 - \\beta_2\\right)\\delta^2$$\n",
    "where $\\beta_2$ is similarly a hyperparameter, and we use this $S_\\delta$ value to update our weights:\n",
    "$$w = w - \\alpha \\frac{\\delta}{\\sqrt{S_\\delta} + \\epsilon}$$\n",
    "where $\\epsilon$ is a really small value to practically prevent division by zero.\n",
    "\n",
    "#### ADAM - Adaptive Moment Estimation\n",
    "\n",
    "Adam is basically the combination of momentum and RMSprop. The algorithm works by computing $V_\\delta$ and $S_\\delta$ in each mini-batch iteration:\n",
    "\n",
    "$$\\begin{align}\n",
    "    V_\\delta & = \\beta_1 V_\\delta + \\left(1 - \\beta_1\\right)\\delta  \\\\\n",
    "    S_\\delta & = \\beta_2 S_\\delta + \\left(1 - \\beta_2\\right)\\delta^2 \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "then a corrected value is generated:\n",
    "\n",
    "$$\\begin{align}\n",
    "    V^{\\textrm{corrected}}_\\delta & = \\frac{V_\\delta}{1 - \\beta_1^t}  \\\\\n",
    "    S^{\\textrm{corrected}}_\\delta & = \\frac{S_\\delta}{1 - \\beta_2^t} \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "where $t$ is the number of the current iteration, finally using the values above, our weight update rule is:\n",
    "\n",
    "$$w = w - \\alpha \\frac{V^{\\textrm{corrected}}_\\delta}{\\sqrt{S^{\\textrm{corrected}}_\\delta} + \\epsilon}$$\n",
    "\n",
    "This update rule has several hyperparameters to tune. The recommended setup by the designers of the algorithm is to fine tune $\\alpha$, use $\\beta_1 = 0.9$, $\\beta_2 = 0.999$ and $\\epsilon = 10^{-8}$.  \n",
    "The name comes from the two types of momentum: $V_\\delta$ is called the first momentum and $S_\\delta$ is the second momentum.\n",
    "\n",
    "\n",
    "#### +1: Learning rate decay\n",
    "\n",
    "As the model approaches the optimum, it is desirable to slow down the speed of the weight change to actually reach the optimum instead of wandering around it.\n",
    "It is a pretty straightforward, and there are many options:\n",
    "$$\\begin{align}\n",
    "    \\alpha & = \\frac{1}{1 + \\textrm{decay_rate} * \\textrm{epoch_num}} \\alpha_0 \\\\\n",
    "    \\alpha & = 0.95^\\text{epoch_num} * \\alpha_0 \\\\\n",
    "    \\alpha & = \\frac{k}{\\sqrt{\\text{epoch_num}}} * \\alpha_0 \\\\\n",
    "    \\alpha & = \\frac{k}{\\sqrt{\\text{t}}} * \\alpha_0\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight initialization\n",
    "\n",
    "#### Vanishing and exploding gradients problem\n",
    "\n",
    "If the initial weigths are larger than 1, the optimization process will incrementally raise it's value. This problem will result huge weight values which leads to problems with the convergence.  \n",
    "The initial weights with smaller than 1 values will in turn always gets smaller by the optimization which will lead to really slow convergence.\n",
    "The described problem is called vanishing and exploding gradients problem.\n",
    "\n",
    "There is a third option however, setting the weights to zero. This, in turn will lead identical weight values over the entire network, basically degrading it's performance.\n",
    "\n",
    "These problems were one of the main roadblock in front of deep learning, and there are several way to mitigate this problem. Let's see some of the ways to select good initial weights for the network.\n",
    "\n",
    "#### Weight initialization method\n",
    "\n",
    "The larger the number of inputs $n$ at layer $l$, the smaller the weights at that layer $w^{l}$ should be. It is a good practice to generate nonzero random initial values with variance of $\\textrm{Var}(w^l) = \\frac{1}{n}$. In case of ReLU activation function, the variance of $\\frac{2}{n}$ yields better results. We can generate such weights by applying:\n",
    "$$w^{l} = w^{l}_{\\textrm{init}} * \\sqrt{\\frac{2}{n^{l-1}}}$$\n",
    "where $l$ is the layer, $n$ is number of inputs and $w_\\textrm{init}$ is randomly generated from the gaussian distribution (eg. using the `np.random.randn()` function). Using **$2$** in the variance and inside the fraction with ReLU activation function is the **He** initializer (named after the author of the paper), while using **$1$** in the variance, and in the fraction and using $\\tanh$ activation function is called the **Xavier** intializer (again, after the author). There are many more variants available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In practice: Keras \n",
    "\n",
    "Everything we talked so far can be implemented by hand from scratch, or we can use one of the several available frameworks. There are several well established and widely used framework available, namely torch, theano, or tensorflow. There is a framework built on top of these low level frameworks, called `Keras` which we'll use to implement our networks.\n",
    "Keras has two APIs:\n",
    "- Sequential API: build the network by creating a list of layers.\n",
    "- Functional API: define the network by chaining layer definitions using layers as input for the consecutive layers.\n",
    "\n",
    "### Using Keras' `Sequential` API\n",
    "\n",
    "In the Sequential API, we are going to define layers, and use those layers to build the final network. Many component can be a layer, layer of neurons, or even activation functions.\n",
    "Once we defined the network layout, we'll compile the network by specifying the optimization method and the network itself, finally train it on training data.\n",
    "\n",
    "#### [Sequential model](https://keras.io/guides/sequential_model/)\n",
    "\n",
    "In order to create the network, we first have to create an empty model by initializing the Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Dense layers](https://keras.io/api/layers/core_layers/dense/)\n",
    "\n",
    "The fully connected layers we used so far are called dense layers in keras. We can define the network 1 layer at the time.  \n",
    "For the initial layer we have to specify the input size, the number of neurons in the layer. For the following layers, the input size is automatically deducted based on the previous layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1 = Dense(2, input_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(hidden_layer_1)\n",
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we added at least one layer, we can also use the `.summary()` function to get more details about the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Activation layers](https://keras.io/api/layers/core_layers/activation/)\n",
    "\n",
    "Notice that we have not defined the activation function for our dense layer previously, so it'll use linear activation function. In order to modify that behaviour, we'll add an activation layer after the dense layer.\n",
    "Using sigmoid activation layer, we can recreate our previously created network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sigmoid_layer_1 = Activation('sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(hidden_sigmoid_layer_1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created the hidden layer with 2 neurons, let's add the final output layer with one (output) neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = Dense(1)\n",
    "output_sigmoid_layer = Activation('sigmoid')\n",
    "model.add(output_layer)\n",
    "model.add(output_sigmoid_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Optimizers](https://keras.io/api/optimizers/)\n",
    "\n",
    "After we defined the layout of the network, we have to select and initialize the optimizer method.  \n",
    "Let's use stochastic gradient descent just like we did previously without momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(learning_rate=0.1, momentum=0.0)\n",
    "print(sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Metrics](https://keras.io/api/metrics/) vs [Loss](https://keras.io/api/losses/)\n",
    "\n",
    "The last part of the network is the selection of loss function and the evaluation metric. *Cost function* is the loss we'd like to minimize during training and *metric* is used to evaluate the trained model. We can set these during the *model compilation*.\n",
    "\n",
    "#### Compilation\n",
    "\n",
    "The last step in the network definition is the model compilation.  \n",
    "It requires three parameters: an optimizer, a loss function, and a list of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Regularization](https://keras.io/api/layers/regularizers/)\n",
    "\n",
    "There are two types of regularization:\n",
    "\n",
    "- weight regularization (eg. l2 normalization)\n",
    "- dropout regularization\n",
    "\n",
    "Weight regularization is available during layer definition, dropout regularization is available as a layer. Let's see an example for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_l2_regularizer = l2(5.0)\n",
    "small_l1_regularizer = l1(0.001)\n",
    "\n",
    "# hidden layer \n",
    "regularized_hidden_layer = Dense(2, input_dim=2, \n",
    "                                 kernel_regularizer=large_l2_regularizer, \n",
    "                                 bias_regularizer=small_l1_regularizer)\n",
    "\n",
    "# dropout\n",
    "hidden_dropout_layer = Dropout(rate=0.5)  # 50% of the neurons\n",
    "\n",
    "# output layer\n",
    "regularized_output_layer = Dense(1, kernel_regularizer=large_l2_regularizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularized_model = Sequential()\n",
    "\n",
    "regularized_model.add(regularized_hidden_layer)\n",
    "regularized_model.add(Activation('sigmoid'))\n",
    "regularized_model.add(hidden_dropout_layer)\n",
    "regularized_model.add(regularized_output_layer)\n",
    "regularized_model.add(Activation('sigmoid'))\n",
    "\n",
    "regularized_model.compile(optimizer=SGD(),\n",
    "                          loss='binary_crossentropy',\n",
    "                          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(regularized_model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example\n",
    "\n",
    "### XOR revisited\n",
    "\n",
    "For the last time, I promise. :)  \n",
    "Let's check train the compiled keras models on this problem.\n",
    "\n",
    "A | B | output |\n",
    "--|---|--------|\n",
    "0 | 0 |  0     |\n",
    "0 | 1 |  1     |\n",
    "1 | 0 |  1     |\n",
    "1 | 1 |  0     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from helpers import plot_results_with_hyperplane, FILL_IN\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "labels = np.array([0, 1, 1, 0])\n",
    "\n",
    "plt.scatter(x=inputs[:, 0], y=inputs[:, 1], c=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "The final step is the training - it is really similar to training any sklearn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(inputs, labels, batch_size=1, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_with_hyperplane(inputs, labels, model, 'Keras.NN [2, 2, 1]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras Scikit-Learn API\n",
    "\n",
    "We can build scikit-learn compatible keras models as well, and we can use it in our pipeline just like any built-in model, including hyperparameter optimization. We can use it through wrapper classes: KerasClassifier for classification and KerasRegressor for regression.  \n",
    "We have to define a build function, which setups the network and compiles it into a model, then pass it to the wrapper object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(learning_rate=0.1, hidden_size=2, activation_function='sigmoid'):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_size, input_dim=2),\n",
    "        Activation(activation_function),\n",
    "        Dense(1),\n",
    "        Activation(activation_function),\n",
    "    ])\n",
    "    optimizer = SGD(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(build(), show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "sklearn_model = KerasClassifier(build, batch_size=1, epochs=1500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.fit(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_with_hyperplane(inputs, labels, sklearn_model, 'Keras.NN [2, 2, 1]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "### Build a handwritten number detector - the MNIST dataset\n",
    "\n",
    "<p><a href=\"https://commons.wikimedia.org/wiki/File:MnistExamples.png\"><img src=\"pics/external/mnist.png\"></a>\n",
    "<br>By <a href=\"//commons.wikimedia.org/w/index.php?title=User:Jost_swd15&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:Jost swd15 (page does not exist)\">Josef Steppan</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=64810040\">Link</a></p>\n",
    "\n",
    "Let's build a classifier on the well known MNIST dataset. It contains 8x8 size pictures about handwritten numbers in grayscale. The goal is to predict which number the user written based on the pixel values.\n",
    "\n",
    "The steps you have to complete are:\n",
    "1. Load data and split into train-test set\n",
    "2. Setup the network:\n",
    "    - one hidden layer with 8 neurons\n",
    "    - one output layer\n",
    "3. Compile the network\n",
    "4. Train data\n",
    "5. Evaluate model\n",
    "\n",
    "#### 1. Load data\n",
    "\n",
    "We have already prepared this step for you. After loading the dataset with the built-in sklearn function split the dataset into a train and a test dataset. Use 1/4 of the data as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "print(y[0])\n",
    "plt.imshow(X[0].reshape(8, 8), cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split the data into train and test dataset:\n",
    "# - use 1/4 of the data as test set\n",
    "# - set the seed to 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = FILL_IN.train_test_split\n",
    "assert X_train.shape == (1347, 64), \"Incorrect split!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setup network\n",
    "\n",
    "We need a network with 1 hidden layer with 8 neurons.\n",
    "\n",
    "Answer the following questions:\n",
    "- What is the dimensionality of the input?\n",
    "- What should be the output activation function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# - Initialize model\n",
    "# - Create the hidden layer with 8 neurons and the proper input dimensionality\n",
    "# - Create a ReLU activation function\n",
    "# - Create the ouput layer\n",
    "# - Select an appropriate activation function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3. Model compilation\n",
    "\n",
    "Initialize the optimizer, select the appropriate loss function and compile the model.\n",
    "\n",
    "Answer the following questions:\n",
    "- Which is the appropriate loss function considering the output activation function and the learning problem?\n",
    "- Which optimizer would be ideal for this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - compile the model by selecting loss function and the optimizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit the model\n",
    "\n",
    "Fit the model using an appropriate batch size and epoch.\n",
    "\n",
    "Answer the following questions:\n",
    "- What would be an ideal batch size?\n",
    "- How many iterations should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - set the batch size to a reasonable size\n",
    "# - set the epoch count to a reasonable number\n",
    "# - fit the model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate model\n",
    "\n",
    "Using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss, final_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'The model final accuracy on test set is {final_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good job!\n",
    "\n",
    "In the next chapter we'll discover how can we deal with high dimensional data (eg. images) when trying to learn their representation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
