{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/DL.png\" width=110 align=\"left\" style=\"margin-right: 10px\">\n",
    "\n",
    "# Introduction to Deep Learning\n",
    "\n",
    "## 10. Home Assignment II.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Extend NN\n",
    "\n",
    "<img src=\"./pics/exercises/adam.gif\" width=400>\n",
    "\n",
    "Extend the NeuralNetwork class implementation with optional regularization and an alternative ADAM solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Fashion MNIST\n",
    "\n",
    "<img src=\"./pics/exercises/fashion.gif\" width=400>\n",
    "\n",
    "Build a convolutional network to classify the fashion mnist dataset. Build a function which will predict the class for an image. The function will get a path of an image as a parameter, it reads the image then returns the predicted class. You can assume that the path will always contain an image, which has *28 x 28 x 4* dimensions.\n",
    "\n",
    "The dataset is available in [keras](https://keras.io/datasets/#fashion-mnist-database-of-fashion-articles). An example image is available at `data/fashion/test.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Newsgroups similarity\n",
    "\n",
    "<img src=\"./pics/exercises/tom_newspaper.gif\" width=400>\n",
    "\n",
    "In our newsgroups example, the model accuracy on the test set was pretty lackluster. Improve the model by creating a more clever trainset, try out FastText embedding and use more topics (preferably all of them). Create a function which receives a document as text, and prints out the `n` most similar document from the newsgroups dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Rock-Paper-Scissors-Lizard-Spock\n",
    "\n",
    "<img src=\"./pics/exercises/rock-paper-scissors-lizard-spock.gif\" width=400>\n",
    "\n",
    "Build a network which is able to play Rock-Paper-Scissors-Lizard-Spock. The input of the network is a low-resolution picture of any of the possible 5 hands and output is also an image which counters the input hand. Feel free to use any kind of pre-existing image / pictogram / drawing /icon as training / test dataset, or even take the pictures yourself.  \n",
    "Suggestion: first build a model using encoded values, and extend your solution once you have a working model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Walking in the GYM \n",
    "\n",
    "<img src=\"./pics/exercises/bipedalwalker.gif\" width=400>\n",
    "\n",
    "Solve the [bipedal walker problem](https://gym.openai.com/envs/BipedalWalker-v2/) using Deep Q-Networks.  \n",
    "The gym environment available as `BipedalWalker-v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
