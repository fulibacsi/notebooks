{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Science \n",
    "## Part XII. - Solving Kaggle's Job Salary prediction competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Read a small sample\n",
    "Note: download and extract the **`Train_rev1.csv`** data file from [kaggle](https://www.kaggle.com/c/job-salary-prediction/data) and rename it to `job_salary_prediction.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(137)\n",
    "with open(\"data/job_salary_prediction.csv\", \"br\") as infile:\n",
    "    numlines = len(infile.readlines())\n",
    "skip_index = random.sample(range(1, numlines), numlines - int(numlines/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/job_salary_prediction.csv\", index_col='Id', skiprows=skip_index)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum() / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'ContractType')\n",
    "print( data.ContractType.unique())\n",
    "print()\n",
    "print( 'ContractTime')\n",
    "print( data.ContractTime.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'ContractType')\n",
    "print( data.ContractType.describe())\n",
    "print()\n",
    "print( 'ContractTime')\n",
    "print( data.ContractTime.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ContractType and ContractTime could be easily inputted, but since the majority of values are the same, we skip it.\n",
    "\n",
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.FullDescription, data.SalaryNormalized, test_size=0.25, random_state=137)\n",
    "\n",
    "df_train, df_test, y_train, y_test = train_test_split(\n",
    "    data, \n",
    "    data.SalaryNormalized,\n",
    "    test_size=0.25, \n",
    "    random_state=137\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## II. Baseline model\n",
    "\n",
    "In order to put our models to context we create a baseline model which represents \"coin toss\" decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Calculate mean value for y.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            not used\n",
    "        y : array-like\n",
    "            target values\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        self.value = y.mean()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Returns calculated mean for every item in X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Input matrix\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like\n",
    "            \"Predicted\" target values for X.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'value'):\n",
    "            raise ValueError(\"Regressor not trained yet. Use fit method first.\")\n",
    "        target_shape = (X.shape[0], )\n",
    "        return np.ones(target_shape) * self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepipe = Pipeline(steps=[\n",
    "    (\"base\", Baseline())\n",
    "])\n",
    "\n",
    "basepipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, basepipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our baseline prediction error. \n",
    "\n",
    "---\n",
    "\n",
    "## III. First model: \n",
    "### Regression model, using only FullDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=0.1, max_df=0.9, stop_words='english')\n",
    "tfidf.fit(data.FullDescription)\n",
    "print(\"Vocabulary size:\", len(tfidf.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linpipe = Pipeline(steps=[\n",
    "    (\"tfidf\", tfidf),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "linpipe.fit(X_train, y_train)\n",
    "\n",
    "print(mean_absolute_error(y_test, linpipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridegpipe = Pipeline(steps=[\n",
    "    (\"tfidf\", tfidf),\n",
    "    (\"rideg\", Ridge(random_state=137))\n",
    "])\n",
    "ridegpipe.fit(X_train, y_train)\n",
    "\n",
    "print(mean_absolute_error(y_test, ridegpipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Hyperparameter optimization\n",
    "\n",
    "Optimize `min_df`, `max_df` and `rideg__alpha` parameters!\n",
    "\n",
    "Don't forget to use the *data.FullDescription* and *data.SalaryNormalized* instead of the train-test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV: Using multiple features\n",
    "\n",
    "Q: What if we need to use different transformations for each feature?  \n",
    "A: ColumnTransformer\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = ColumnTransformer([\n",
    "    ('count', CountVectorizer(), 'Title'),\n",
    "    ('tfidf', TfidfVectorizer(min_df=0.1, max_df=0.9, stop_words='english'), 'FullDescription')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulti_lin_pipe = Pipeline([\n",
    "    ('union', feat),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "ulti_lin_pipe.fit(df_train, y_train)\n",
    "\n",
    "print(mean_absolute_error(y_test, ulti_lin_pipe.predict(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulti_rideg_pipe = Pipeline([\n",
    "    ('union', feat),\n",
    "    ('rideg', Ridge(random_state=137))\n",
    "])\n",
    "ulti_rideg_pipe.fit(df_train, y_train)\n",
    "\n",
    "print(mean_absolute_error(y_test, ulti_rideg_pipe.predict(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulti_rideg_pipe = Pipeline([\n",
    "    ('union', feat),\n",
    "    ('rideg', Ridge(random_state=137))\n",
    "])\n",
    "ulti_rideg_pipe.fit(df_train, y_train)\n",
    "\n",
    "print(mean_absolute_error(y_test, ulti_rideg_pipe.predict(df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise II: Add more columns\n",
    "\n",
    "Following the same process, add every reasonable column with preprocessing to the pipelines and inspect `LinearRegression` and `Ridge` errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise III: Hyperparameter optimization\n",
    "\n",
    "Find the previously assembled pipeline's optimal parameters. To easily find the correct parameter names use the pipeline's `get_params` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ulti_rideg_pipe_param_names = ulti_rideg_pipe.get_params().keys()\n",
    "\n",
    "print(\"ulti_rideg_pipe's parameter names:\")\n",
    "print('-', '\\n- '.join(ulti_rideg_pipe_param_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "szisz_ds_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
