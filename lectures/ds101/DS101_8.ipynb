{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Science\n",
    "## Part VIII. - Deep Learning and it's applications\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "- #### Deep learning basics\n",
    "    - <a href=\"#What-is-Deep-Learning?\">Theory</a>\n",
    "    - <a href=\"#1.-Architectures\">Layer Architecture types</a>\n",
    "        - Dense Neural Networks\n",
    "            - Activision and Loss Functions\n",
    "        - Convolutional Neural Networks\n",
    "        - Recurrent Neural Networks\n",
    "        - Word Embeddings\n",
    "        - Regularization\n",
    "    \n",
    "---\n",
    "\n",
    "# I. Deep learning basics\n",
    "\n",
    "## What is Deep Learning?\n",
    "\n",
    "> _Deep learning refers to neural networks with multiple hidden layers that can learn increasingly abstract representations of the input data._ [source](https://elitedatascience.com/keras-tutorial-deep-learning-in-python)\n",
    "\n",
    "> _Deep learning is a class of neural network algorithms that:_\n",
    "> - _use a cascade of __multiple layers__ of nonlinear processing units for feature extraction and transformation. Each successive layer uses the output from the previous layer as input._\n",
    "> - _learn in supervised (e.g., classification) and/or unsupervised (e.g., pattern analysis) manners._\n",
    "> - _learn __multiple levels of representations__ that correspond to __different levels of abstraction__; the levels form a hierarchy of concepts._ \n",
    "[source](https://en.wikipedia.org/wiki/Deep_learning#Definition)\n",
    "\n",
    "## Why is it important?\n",
    "\n",
    "Deep Learning is widely used in our daily lives. It powers web search engines, recommender systems, image recognition systems, self driving cars. It helps generating sound, image, text, better ai agents.  \n",
    "It is the current state of the art machine learning model for many tasks including image recognition, text mining, and classification.\n",
    "\n",
    "## Tools\n",
    "- Scikit-Learn\n",
    "- Gensim\n",
    "- Tensorflow\n",
    "- Torch\n",
    "- Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Deep Neural Network Architectures\n",
    "\n",
    "## [Dense feedforward network](https://keras.io/layers/core/#dense)\n",
    "\n",
    "A dense layer is just a regular layer of neurons in a neural network. Each neuron recieves input from all the neurons in the previous layer, thus densely connected. The layer has a weight matrix W, a bias vector b, and the activations of previous layer a. The following is te docstring of class Dense from the keras documentation:\n",
    "\n",
    "output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer.\n",
    "\n",
    "### [Activision functions](https://keras.io/activations/)\n",
    "\n",
    "- Sigmoid: $\\frac{{\\rm e}^x}{{\\rm e}^x + 1}$\n",
    "- Tanh: $\\tanh(x)$\n",
    "- ReLU: $\\max(x, 0)$\n",
    "- Softmax:  $\\frac{{\\rm e}^x}{\\sum{{\\rm e}^x}}$\n",
    "- Hierarchical Softmax\n",
    "\n",
    "#### Further reading:\n",
    "\n",
    "- https://medium.com/@srnghn/deep-learning-overview-of-neurons-and-activation-functions-1d98286cf1e4\n",
    "- https://www.analyticsvidhya.com/blog/2017/10/fundamentals-deep-learning-activation-functions-when-to-use-them/\n",
    "- http://cs231n.github.io/neural-networks-1/#commonly-used-activation-functions\n",
    "- https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8\n",
    "- https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\n",
    "\n",
    "### [Loss functions](https://keras.io/losses/)\n",
    "\n",
    "- MSE: mean squared error $\\frac{\\sum{e^2}}{n}$\n",
    "- MAE: mean absolute error $\\frac{\\sum{\\left|{e}\\right|}}{n}$\n",
    "- Categorical Hinge Loss: $\\max(0, 1 - t*y)$\n",
    "- Cross Entropy Loss: $V(f(x), t) = -t\\ln(f(x))-(1-t)\\ln(1-f(x))$, where $ {\\displaystyle t=(1+y)/2}$\n",
    "- Cosine proximity\n",
    "\n",
    "#### Further reading:\n",
    "\n",
    "- http://cs231n.github.io/neural-networks-2/#loss-functions\n",
    "- http://cs231n.github.io/neural-networks-3/#loss\n",
    "- https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23\n",
    "- https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8\n",
    "\n",
    "\n",
    "### [Regularization](https://chatbotslife.com/regularization-in-deep-learning-f649a45d6e0)\n",
    "\n",
    "There are many different kind of regularization techniques available in most of the deep learning frameworks.\n",
    "\n",
    "#### Early stopping\n",
    "\n",
    "Early stopping is a simple method which checks a loss criteria on a validation dataset during the training process. If the criteria stops decreasing, the training ends as well. A patience parameter can be set to allow non-improving steps which helps to move out from local minima.\n",
    "\n",
    "#### Dropout\n",
    "\n",
    "<img src=\"pics/dl_dense_dropout_network.png\" width=500>By <a href=\"http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf\">Srivastava, Nitish, et al. ”Dropout: a simple way to prevent neural networks from overfitting”, JMLR 2014</a>\n",
    "\n",
    "Dropout is a a technique used to tackle Overfitting. The Dropout method in keras.layers module takes in a float between 0 and 1, which is the fraction of the neurons to drop. Below is the docstring of the Dropout method from the documentation:\n",
    "\n",
    "Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "\n",
    "#### Weight penalty\n",
    "\n",
    "Simple L1 (absolute value) or L2 (quadratic value) regularization term in the objective function.\n",
    "\n",
    "#### Further reading:\n",
    "\n",
    "- http://cs231n.github.io/neural-networks-2/#reg\n",
    "\n",
    "---\n",
    "\n",
    "### In Practice\n",
    "#### Building a simple dense network to classify hand-written digits\n",
    "\n",
    "#### 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "yt = OneHotEncoder(categories='auto', sparse=False).fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, yt, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(8, activation='relu', input_dim=64),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.a Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(Xtrain, ytrain, # training data\n",
    "          batch_size=16,  # number of data points to use in a training round\n",
    "          epochs=100,     # number of full training cycle \n",
    "          validation_data=(Xtest, ytest),  # validation dataset\n",
    "          callbacks=[EarlyStopping(patience=3), \n",
    "                     TensorBoard(log_dir='tensor', histogram_freq=0, write_graph=True,\n",
    "                                 write_images=True, update_freq='epoch')])  # function to execute at the end of each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(Xtest, ytest)\n",
    "print(f'test loss: {loss}, test acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Build a classification model for the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### [Convolutional Neural Network (CNN)](https://keras.io/layers/convolutional/)\n",
    "\n",
    "<img src=\"pics/dl_cnn.png\" width=600 alt=\"Typical cnn.png\"><br>By <a href=\"//commons.wikimedia.org/w/index.php?title=User:Aphex34&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:Aphex34 (page does not exist)\">Aphex34</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=45679374\">Link</a>\n",
    "\n",
    "> _Convolutional Neural Networks are very similar to ordinary Neural Networks: they are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer and all the tips/tricks we developed for learning regular Neural Networks still apply._  \n",
    " _So what changes? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network._ - [source](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "> _Convolutional Neural Networks have a different architecture than regular Neural Networks. Regular Neural Networks transform an input by putting it through a series of hidden layers. Every layer is made up of a set of neurons, where each layer is fully connected to all neurons in the layer before. Finally, there is a last fully-connected layer — the output layer — that represent the predictions._  \n",
    " _Convolutional Neural Networks are a bit different. First of all, the layers are organised in 3 dimensions: width, height and depth. Further, the neurons in one layer do not connect to all the neurons in the next layer but only to a small region of it. Lastly, the final output will be reduced to a single vector of probability scores, organized along the depth dimension._ - [source](https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050)\n",
    "\n",
    "A Convolutional Neural Network consists of different building blocks:\n",
    "- Convolutional layers: feature extraction\n",
    "- Pooling layers: feature selection\n",
    "- Dense layers: classification\n",
    "\n",
    "#### Convolution layer\n",
    "\n",
    "A filtering layer with a learnable filter. It's purpose is to detect features in the input. In case of images these features could be edges, or even shapes. \n",
    "\n",
    "> _In mathematics convolution is a mathematical operation on two functions (f and g) to produce a third function that expresses how the shape of one is modified by the other._ - [source](https://en.wikipedia.org/wiki/Convolution)\n",
    "\n",
    "<img src=\"pics/dl_convolution.gif\" alt=\"Convolution of box signal with itself2.gif\"><br>By <a href=\"//commons.wikimedia.org/wiki/File:Convolution_of_box_signal_with_itself.gif\" title=\"File:Convolution of box signal with itself.gif\">Convolution_of_box_signal_with_itself.gif</a>: Brian Amberg\n",
    "derivative work: <a href=\"//commons.wikimedia.org/wiki/User:Tinos\" title=\"User:Tinos\">Tinos</a> (<a href=\"//commons.wikimedia.org/wiki/User_talk:Tinos\" title=\"User talk:Tinos\"><span class=\"signature-talk\">talk</span></a>) - <a href=\"//commons.wikimedia.org/wiki/File:Convolution_of_box_signal_with_itself.gif\" title=\"File:Convolution of box signal with itself.gif\">Convolution_of_box_signal_with_itself.gif</a>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\" title=\"Creative Commons Attribution-Share Alike 3.0\">CC BY-SA 3.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=11003835\">Link</a></p>\n",
    "\n",
    "> _We execute a convolution by sliding the filter over the input. At every location, a matrix multiplication is performed and sums the result onto the feature map._ \n",
    "_In the animation below, you can see the convolution operation. You can see the filter (the green square) is sliding over our input (the blue square) and the sum of the convolution goes into the feature map (the red square)._ - [source](https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050)\n",
    "\n",
    "<div style=\"display: inline-block;\">\n",
    "<img src=\"pics/dl_sliding_window.gif\" width=400 align='left'>\n",
    "<img src=\"pics/dl_filter.png\" width=400 align='left'>\n",
    "</div>\n",
    "\n",
    "<div style='align: clear'>\n",
    "<br>\n",
    "Animation by <a href=\"https://towardsdatascience.com/@ardendertat\">Arden Dertat</a>, <a href=\"https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\">Link</a> \n",
    "Image by <a href=\"https://towardsdatascience.com/@ardendertat\">Arden Dertat</a>, <a href=\"https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\">Link</a>\n",
    "</div>\n",
    "\n",
    "The three main parameter to watch out in convolutional layer is:\n",
    "\n",
    "- __depth__: The number of filters we'd like to use\n",
    "- __stride__: The size of the step the convolution filter moves each time\n",
    "- __padding__: the size of the zero-padding around the input\n",
    "\n",
    "#### Pooling layer\n",
    "\n",
    "<img src=\"pics/dl_pooling.png\" width=400><br>By <a href=\"https://cs.stanford.edu/people/karpathy/\">Andrej Karpathy</a>, <a href=\"http://cs231n.github.io/convolutional-networks/\">Link</a>\n",
    "\n",
    "Pooling is much more straightforward: It reduces the dimensionality of the input by downsampling it. It defines a window size and an aggregation function to create an approximate output of the input. Using a poolig layer prevents overfitting, reduces the number of weights in the consecutive layers, shortens training time, and also keeps the important informations. The most common aggregation function is __max__.\n",
    "\n",
    "#### Fully-connected layer\n",
    "\n",
    "Regular fully connected layer with proper loss function.\n",
    "\n",
    "#### Further reading:\n",
    "\n",
    "- https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050\n",
    "- http://cs231n.github.io/convolutional-networks/\n",
    "- https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\n",
    "- https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/\n",
    "- https://github.com/ardendertat/Applied-Deep-Learning-with-Keras/blob/master/notebooks/Part%204%20%28GPU%29%20-%20Convolutional%20Neural%20Networks.ipynb\n",
    "\n",
    "---\n",
    "\n",
    "### In Practice\n",
    "\n",
    "#### Build a CNN classifier for the hand digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of cases, width, height, channels (rgb)\n",
    "Xt = X.reshape((X.shape[0], 8, 8, 1))\n",
    "yt = OneHotEncoder(categories='auto', sparse=False).fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xt, yt, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Xt[1, :, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=(8, 8, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(Xtrain, ytrain, # training data\n",
    "          batch_size=16,  # number of data points to use in a training round\n",
    "          epochs=100,     # number of full training cycle \n",
    "          validation_data=(Xtest, ytest),  # validation dataset\n",
    "          callbacks=[EarlyStopping(patience=3)])  # function to execute at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(Xtest, ytest)\n",
    "print(f'test loss: {loss}, test acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Build a CNN for the MNIST classification problem\n",
    "\n",
    "In case you stuck in the process, use [this](https://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_cnn.py) [tutorial]((https://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_x, img_y = 28, 28\n",
    "\n",
    "# load the MNIST data set, which already splits into train and test sets for us\n",
    "(Xtrain, ytrain), (Xtest, ytest) = mnist.load_data()\n",
    "\n",
    "# because the MNIST is greyscale, we only have a single channel\n",
    "Xtrain = Xtrain.reshape()  # TODO: fill in the required shape \n",
    "Xtest = Xtest.reshape()    # TODO: fill in the required shape \n",
    "input_shape = ()           # TODO: fill in the required shape \n",
    "\n",
    "# keras built-in OneHotEncoder solution\n",
    "ytrain = to_categorical(ytrain, num_classes)\n",
    "ytest = to_categorical(ytest, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first image in Xtrain with sns.heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model here\n",
    "model = Sequential([\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### [Recurrent Neural Networks (RNN)](https://keras.io/layers/recurrent/)\n",
    "\n",
    "<img src=\"pics/dl_rnn.svg\" alt=\"Recurrent neural network unfold.svg\" height=\"213\" width=\"640\"><br>By <a href=\"//commons.wikimedia.org/wiki/User:Ixnay\" title=\"User:Ixnay\">François Deloche</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=60109157\">Link</a></p>\n",
    "\n",
    "> _A recurrent neural network (RNN) is a class of artificial neural network where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Unlike feedforward neural networks, RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition._ - [source](https://en.wikipedia.org/wiki/Recurrent_neural_network)\n",
    "\n",
    "So, basically the neuron has memory and remembers it's previous informations by using the results of the previous inputs. \n",
    "> _A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor. Consider what happens if we unroll the loop: as you can see above, this chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists._ - [source](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) \n",
    "\n",
    "The biggest problem with this setup is easily understood, if we consider the following sentence: \"I grew up in _France_... that's why I speak fluent _French_.\" The related information are far away from each other and it's easy for the network to miss these nuances and however in theory they can learn them, but in practice they often unable to do so.  \n",
    "But a more complex version of them is able to overcome this difficulty, they're called LSTMs.\n",
    "\n",
    "#### [Long-Short Term Memory (LSTM) Networks](https://keras.io/layers/recurrent/#lstm)\n",
    "\n",
    "They are build to have long term memory, and have the same kind of chained structure, but the modules themselves are different.\n",
    "\n",
    "<img src=\"pics/dl_lstm.png\" width=\"600\"><br>By <a href=\"https://colah.github.io/about.html\">Christopher Olah</a>, <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Link</a>\n",
    "\n",
    "> _Long short-term memory (LSTM) is an artificial recurrent neural network, (RNN) architecture used in the field of deep learning. Unlike standard feedforward neural networks, LSTM has feedback connections that make it a \"general purpose computer\" (that is, it can compute anything that a Turing machine can). It can not only process single data points (such as images), but also entire sequences of data (such as speech or video). For example, LSTM is applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition. Bloomberg Business Week wrote: \"These powers make LSTM arguably the most commercial AI achievement, used for everything from predicting diseases to composing music.\"_  \n",
    "_A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell._  \n",
    "_LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series. LSTMs were developed to deal with the exploding and vanishing gradient problems that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models and other sequence learning methods in numerous applications._ - [source](https://en.wikipedia.org/wiki/Long_short-term_memory)\n",
    "\n",
    "\n",
    "It's main building blocks are:\n",
    "- Cell state — Acts as a highway that transports relative information along the sequence chain.\n",
    "- Forget gate — Decides which information should be kept and which should be discarded.\n",
    "- Input gate — Updates the cell state.\n",
    "- Output gate — Decides what the next hidden state(contains information on previous inputs) should be.\n",
    "\n",
    "#### Further reading:\n",
    "\n",
    "- https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "- https://medium.com/datadriveninvestor/a-high-level-introduction-to-lstms-34f81bfa262d\n",
    "- https://skymind.ai/wiki/lstm\n",
    "- https://www.dlology.com/blog/how-to-use-return_state-or-return_sequences-in-keras/\n",
    "\n",
    "---\n",
    "\n",
    "### In Practice\n",
    "\n",
    "#### Build a sentiment predictor on movie reviews\n",
    "\n",
    "Based on [this](https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.datasets import imdb\n",
    "\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 500\n",
    "# pad sequences will fill every doc in the corpus to a given length\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=top_words,                 # number of words in the vocab\n",
    "              output_dim=embedding_vector_length,  # size of the embedding vector\n",
    "              input_length=max_review_length),     # size of the documents\n",
    "    LSTM(units=100),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print('test loss: {}, test accuracy: {}'.format(*score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Predict simulated stock prices\n",
    "\n",
    "Follow this [tutorial](https://stackabuse.com/time-series-analysis-with-lstm-using-pythons-keras-library/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### [Word](https://keras.io/layers/embeddings/) [Embeddings](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "\n",
    "<div style=\"display: inline-block;\">\n",
    "<img src=\"pics/dl_king_queen_embedding.png\" width=400 align='left'>\n",
    "<img src=\"pics/dl_king_queen_composition.png\" width=400 align='left'>\n",
    "</div>\n",
    "\n",
    "<div style='align: clear'/>\n",
    "<br>Images from <a href=\"https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/\">the morning paper</a>\n",
    "\n",
    "> _Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension._  \n",
    "_Methods to generate this mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, explainable knowledge base method, and explicit representation in terms of the context in which words appear._ - [source](https://en.wikipedia.org/wiki/Word_embedding)\n",
    "\n",
    "The intuition to the model is that words with similar contexts have similar meaning.\n",
    "\n",
    "#### Training\n",
    "\n",
    "<div style=\"display: inline-block;\">\n",
    "<img src=\"pics/dl_w2v_training_data.png\" width=300 align='left'>\n",
    "<img src=\"pics/dl_w2v_skip_grams.png\" width=300 align='left'>\n",
    "<img src=\"pics/dl_w2v_weight_matrix.png\" width=300 align='left'>\n",
    "</div>\n",
    "\n",
    "<div style='align: clear'/>\n",
    "<br>Images from <a href=\"http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\">Word2Vec Tutorial - The Skip-Gram Model.</a>, by <a href=\"http://mccormickml.com/\">Chris McCormick</a>\n",
    "\n",
    "There are two approach to learn word-embeddings: \n",
    "- the continous bag-of-words (CBOW): the model predicts the selected word from the context words in the surrounding window (word order invariant)\n",
    "- the skip-gram architecture:  the model predicts the context words from the selected word (context words are weighted by their distance to the selected word)\n",
    "\n",
    "\n",
    "#### Further reading:\n",
    "\n",
    "- https://www.tensorflow.org/tutorials/representation/word2vec#vector-representations-of-words\n",
    "- https://www.quora.com/How-does-word2vec-work-Can-someone-walk-through-a-specific-example\n",
    "- http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "- https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa\n",
    "- https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526\n",
    "- https://hackernoon.com/word-embeddings-in-nlp-and-its-applications-fab15eaf7430\n",
    "- https://blog.cambridgespark.com/tutorial-build-your-own-embedding-and-use-it-in-a-neural-network-e9cde4a81296\n",
    "- https://skymind.ai/wiki/word2vec\n",
    "- https://github.com/anvaka/word2vec-graph\n",
    "- https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "- https://heartbeat.fritz.ai/using-a-keras-embedding-layer-to-handle-text-data-2c88dc019600\n",
    "- [Google Word2Vec](https://code.google.com/archive/p/word2vec/)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### In Practice\n",
    "\n",
    "#### Learning simple word-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "\n",
    "labels = np.array([1, 1, 1, 1, 1,\n",
    "                   0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 8, input_length=max_length),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "score = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('loss: {}, accuracy: {}'.format(*score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"good effort\"\n",
    "enc_text = [one_hot(text, vocab_size)]\n",
    "pad_text = pad_sequences(enc_text, maxlen=max_length, padding='post')\n",
    "pred_text = model.predict_classes(pad_text)\n",
    "\n",
    "text, enc_text, pad_text, pred_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: News classification\n",
    "\n",
    "Classify the 20newsgroups dataset while building an embedding. As a first step, try to separate the atheism documents (`alt.atheism`) from the christian documents (`soc.religion.christian`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Further tutorials:\n",
    "- https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/\n",
    "- https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "- https://www.datacamp.com/community/tutorials/deep-learning-python\n",
    "- https://elitedatascience.com/keras-tutorial-deep-learning-in-python\n",
    "- https://www.guru99.com/keras-tutorial.html\n",
    "- https://github.com/adventuresinML/adventures-in-ml-code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
